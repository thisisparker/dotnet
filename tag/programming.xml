<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://thisisparker.github.io/dotnet/tag/programming.xml" rel="self" type="application/atom+xml" /><link href="https://thisisparker.github.io/dotnet/" rel="alternate" type="text/html" /><updated>2022-09-18T17:46:58-04:00</updated><id>https://thisisparker.github.io/dotnet/tag/programming.xml</id><title type="html">parker higgins dot net</title><subtitle></subtitle><author><name>Parker Higgins</name></author><entry><title type="html">Introducing: cursewords, a crossword puzzle solving interface for the terminal</title><link href="https://thisisparker.github.io/dotnet/2019/03/cursewords-crossword-puzzle-solving-interface-terminal/" rel="alternate" type="text/html" title="Introducing: cursewords, a crossword puzzle solving interface for the terminal" /><published>2019-03-03T13:55:35-05:00</published><updated>2019-03-03T13:55:35-05:00</updated><id>https://thisisparker.github.io/dotnet/2019/03/cursewords-crossword-puzzle-solving-interface-terminal</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2019/03/cursewords-crossword-puzzle-solving-interface-terminal/"><![CDATA[<p>I’m releasing <a href="https://github.com/thisisparker/cursewords">new software today for solving crossword puzzles in the terminal</a>. <code class="language-plaintext highlighter-rouge">cursewords</code> is a small Python program to open, navigate, and solve puzzles stored as .puz files. If you’re a Mac or Linux user, you can install it today by running <code class="language-plaintext highlighter-rouge">pip3 install --user cursewords</code> in your terminal, and then use the <code class="language-plaintext highlighter-rouge">cursewords</code> command to open a .puz file on your computer.</p>

<p>In case you’re not a crossword nerd: the .puz file was developed for popular solving software called AcrossLite, and it remains the most popular format for transmitting crosswords online, from independent creators all the way up to the <em>New York Times</em>.</p>

<figure><img src="https://parkerhiggins.net/wp-content/uploads/2019/03/demo.gif" /><figcaption>cursewords in action on my terminal</figcaption></figure>

<p>In fact, many independent puzzle creators <em>only</em> distribute their puzzles as digital files. For example, I subscribe to a handful of excellent puzzle outlets—<a href="https://avxwords.com/#/">American Values Club</a>, <a href="https://inkubatorcrosswords.com/">The Inkubator</a>, <a href="https://www.crosswordnation.com/">Crossword Nation</a>, <a href="http://www.fireballcrosswords.com/">Fireball Crosswords</a>—that don’t offer an online solver or an app like the <em>Times</em> does. As a Linux user, I didn’t have a lot of options to open them: AcrossLite isn’t compatible, Web-based solutions have their limitations, and beyond that, I wanted to be able to introduce fun features like a “downs only” mode that hides the across clues. (You can try it: running <code class="language-plaintext highlighter-rouge">cursewords</code>with the <code class="language-plaintext highlighter-rouge">--downs-only</code> flag activates this very challenging mode.)</p>

<p>But also, I liked the challenge of writing my own software as a way of thinking more about how crosswords are built and how we hold them in our head for navigation. I also love the retro-computing aesthetic that comes with terminal applications, and—while I think this is the first ever terminal crossword client—that it’s mostly based on tech that has remained unchanged for decades. In that way I’ve likened it to efforts to, say, imagine what <a href="https://jalopnik.com/the-greeks-had-the-technology-to-build-a-car-in-60-a-d-5888188">a car built with first-century technology would look like</a>: it’s not necessarily the most useful or the best, but it’s instructive (and in my case, actually works)!</p>

<p>As the name may suggest, <code class="language-plaintext highlighter-rouge">cursewords</code> relies on a famed <a href="https://en.wikipedia.org/wiki/Curses_(programming_library)">programming library called curses</a> that helps to build text-based user interfaces. It is also heavily indebted to <a href="https://github.com/jquast/blessed">a curses wrapper called blessed</a>, and <a href="https://github.com/alexdej/puzpy">a library called puz that reads and writes .puz files</a>.</p>

<p>If you’re interested in <code class="language-plaintext highlighter-rouge">cursewords</code>, please give it a try and let me know how it works for you. I’ve been very interested in how to solve this problem for over a month now and I am excited to talk about it more publicly.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="computers" /><category term="crosswords" /><category term="cursewords" /><category term="new york times" /><category term="programming" /><category term="python" /><summary type="html"><![CDATA[I’m releasing new software today for solving crossword puzzles in the terminal. cursewords is a small Python program to open, navigate, and solve puzzles stored as .puz files. If you’re a Mac or Linux user, you can install it today by running pip3 install --user cursewords in your terminal, and then use the cursewords command to open a .puz file on your computer.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://thisisparker.github.io/dotnet/wp-content/uploads/2019/03/Screenshot_2019-03-03_13-05-40.png" /><media:content medium="image" url="https://thisisparker.github.io/dotnet/wp-content/uploads/2019/03/Screenshot_2019-03-03_13-05-40.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Shutting down @LinkArchiver, the Twitter link backup bot</title><link href="https://thisisparker.github.io/dotnet/2018/08/shutting-down-linkarchiver-the-twitter-link-backup-bot/" rel="alternate" type="text/html" title="Shutting down @LinkArchiver, the Twitter link backup bot" /><published>2018-08-26T18:13:52-04:00</published><updated>2018-08-26T18:13:52-04:00</updated><id>https://thisisparker.github.io/dotnet/2018/08/shutting-down-linkarchiver-the-twitter-link-backup-bot</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2018/08/shutting-down-linkarchiver-the-twitter-link-backup-bot/"><![CDATA[<p>After a little over a year of service, @LinkArchiver, the Twitter bot that <a href="https://parkerhiggins.net/2017/07/linkarchiver-a-new-bot-to-back-up-tweeted-links/">automatically made Internet Archive backups</a> of the links you tweeted, has archived its last link. In that time it archived somewhere around 7.2 million links total from about 9,000 users.((“Quote tweets” are treated like links to tweets, and constituted about a third of the total links. Something like 4.8 million links backed up were at domains other than Twitter.)) The last link it archived was <a href="http://www.latimes.com/local/lanow/la-me-ln-data-throttling-20180822-story.html">this LA Times story about Verizon throttling California firefighters</a>, <a href="https://twitter.com/elizs/status/1032644299144527872">tweeted on Thursday morning</a>.</p>

<p>LinkArchiver stopped working this week when <a href="https://twittercommunity.com/t/details-and-what-to-expect-from-the-api-deprecations-this-week-on-august-16-2018/110746">Twitter turned off the User Stream API</a> that it relied on. Under the hood, LinkArchiver was only looking at its timeline, so it could use Twitter’s built-in following features to make its user list. Since that API change, it can’t pull down a “stream” of its timeline, and so would have to be redesigned to continue to work.</p>

<p>Even as this project is shutting down, I consider it a pretty major success. I am very grateful to Jacob Hoffman-Andrews for <a href="https://twitter.com/j4cob/status/883054720260087808">pitching me the underlying idea</a>. Writing <a href="https://github.com/thisisparker/linkarchiver/">the code</a> (and seeing it get an enthusiastic reception) was a great way to kick off my time at Recurse Center last summer. I’m also grateful to Ben Cotton who gave it a <a href="https://opensource.com/article/17/7/linkarchiver-automatically-submits-links-internet-archive">nice write-up at opensource.com</a> when it launched.</p>

<p>I’ve had a few people ask me about archiving and backup options now that this is no longer available. I’m considering doing something similar for Mastodon, or for plain RSS feeds, but I also don’t want to downplay the fact that Internet Archive does a very good job of running the Wayback Machine crawler, and so the main value I can add is adding a personal layer. In any future work on things like LinkArchiver, I’d want to keep track of that.</p>

<p>There’s also a way to do a Twitter redesign with existing APIs, probably. Instead of getting a stream from Twitter that pinged on new tweet events, it could request new tweets at regular intervals, using an API that’s still operational. If somebody wants to write that, they’re welcome to, but <a href="https://slate.com/technology/2018/08/twitters-new-developer-guidelines-might-end-fun-bot-accounts.html">given the way Twitter is</a>, I’m not eager to do so.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="bots" /><category term="programming" /><category term="twitter" /><summary type="html"><![CDATA[After a little over a year of service, @LinkArchiver, the Twitter bot that automatically made Internet Archive backups of the links you tweeted, has archived its last link. In that time it archived somewhere around 7.2 million links total from about 9,000 users.((“Quote tweets” are treated like links to tweets, and constituted about a third of the total links. Something like 4.8 million links backed up were at domains other than Twitter.)) The last link it archived was this LA Times story about Verizon throttling California firefighters, tweeted on Thursday morning.]]></summary></entry><entry><title type="html">Pulling free and open weather data</title><link href="https://thisisparker.github.io/dotnet/2017/09/pulling-free-and-open-weather-data-in-python/" rel="alternate" type="text/html" title="Pulling free and open weather data" /><published>2017-09-22T16:41:19-04:00</published><updated>2017-09-22T16:41:19-04:00</updated><id>https://thisisparker.github.io/dotnet/2017/09/pulling-free-and-open-weather-data-in-python</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/09/pulling-free-and-open-weather-data-in-python/"><![CDATA[<p>When I decided to add realtime weather effects to <a href="https://www.twitter.com/choochoobot">@choochoobot</a>, I knew there were a few qualities I wanted to find in a data source. Ideally I would find something free and reliable that didn’t require me to agree to many developer terms or sign up for an API token. Google <a href="https://www.programmableweb.com/news/google-weather-api/2012/08/28">shuttered its undocumented Weather API</a> in 2012, and Yahoo’s offering, which has changed a few times over the years, now requires an account and a consumer key and secret.</p>

<p>It took some poking around but I was eventually successful, and now @choochoobot should correctly show clouds, rain, snow, or thunderstorms, depending on whether observations in New York at the moment it’s tweeting.</p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2017/09/Screenshot_2017-09-22_15-46-34.png" alt="" /></p>

<p>Current observed weather conditions seems to me like something that should be provided by the government as open data. Fortunately, that intuition was correct: free realtime weather data is openly available, if you know where to look.</p>

<p>The National Weather Service, an agency within NOAA, provides weather observations from stations all over the US in RSS and parseable XML formats. And while parsing XML in Python isn’t exactly pleasant, it’s straightforward enough and I am now able to get qualitative descriptions of the current weather that I can translate into emoji. Here’s <a href="https://github.com/thisisparker/choochoobot/blob/master/choochoogen.py#L62-L86">the relevant code</a>, and here’s how it works:</p>

<ul>
  <li>Each time @choochoobot tweets, it checks to see whether it’s daytime or nighttime. If it’s nighttime, I skip the weather check and instead calculate the phase and placement of the moon in the sky.</li>
  <li>If it’s during the day, I make download the <a href="http://w1.weather.gov/xml/current_obs/KNYC.xml">XML file provided by the KNYC weather station</a> in Central Park. You can load the same file in your browser at any point, but you probably have to view-source to see it in a reasonable human-readable format. That’s one of about <a href="http://w1.weather.gov/xml/current_obs/">1,800 locations in US states and territories</a> that the NWS provides information for.</li>
  <li><span class="citation">@choochoobot</span> then parses the XML file using Python’s built-in <a href="https://docs.python.org/3.5/library/xml.etree.elementtree.html">ElementTree XML API</a>. The relevant field for my purposes is labeled “weather”, which contains a text description of the observed conditions.</li>
  <li>At least in theory, that phrase will always be one of the 250 or so pre-set descriptions <a href="http://w1.weather.gov/xml/current_obs/weather.php">provided by the the NWS</a>. These are sort of grouped into categories—there’s a pretty clear thunderstorm grouping, and one for hail—but it seems a bit ad hoc. My use requires classifying the observed weather into just four or five buckets with matching emoji; I just made a big list of terms that I’d take to mean “cloudy,” for example, and checked to see whether the observed weather phrase was on that list.</li>
  <li>Then I pick emoji for the sky, and put the whole tweet together. If the weather is cloudy, I replace the sun emoji with a sun-behind-clouds emoji. Real scientific stuff.</li>
</ul>

<p>In case it’s useful, I’ve converted the NWS list of <a href="https://github.com/dariusk/corpora/pull/278">weather conditions to JSON</a> and submitted it to Darius Kazemi’s corpora project. Once that gets merged in, those weather conditions will all be available that way.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="bots" /><category term="howto" /><category term="programming" /><category term="python" /><category term="twitter" /><category term="weather" /><summary type="html"><![CDATA[When I decided to add realtime weather effects to @choochoobot, I knew there were a few qualities I wanted to find in a data source. Ideally I would find something free and reliable that didn’t require me to agree to many developer terms or sign up for an API token. Google shuttered its undocumented Weather API in 2012, and Yahoo’s offering, which has changed a few times over the years, now requires an account and a consumer key and secret.]]></summary></entry><entry><title type="html">Which states hated Wesley?</title><link href="https://thisisparker.github.io/dotnet/2017/09/which-states-hated-wesley/" rel="alternate" type="text/html" title="Which states hated Wesley?" /><published>2017-09-08T15:20:59-04:00</published><updated>2017-09-08T15:20:59-04:00</updated><id>https://thisisparker.github.io/dotnet/2017/09/which-states-hated-wesley</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/09/which-states-hated-wesley/"><![CDATA[<p>One of my goals while at Recurse Center has been to improve my ability to manipulate and visualize data sets. To that end, I’ve been toying around with the <a href="https://www.ssa.gov/oact/babynames/limits.html">Social Security Administration’s baby name dataset</a>, which records the number of babies born with each given name every year, both federally and at the state level. Because I’ve also been watching <em>Star Trek: The Next Generation</em> along with the <a href="http://foreverdogproductions.com/fdpn/podcasts/treks-and-the-city/">Treks And The City podcast</a>, I chose to dig into information about the name “Wesley.”</p>

<p>On my first pass through the data I noticed that the name’s popularity dramatically spiked around 1976, and then tapered off for a few decades after. Honestly, that spike is the most interesting property of the whole graph, and I can’t explain it very well. But a funny secondary effect is that neither <em>TNG</em>‘s premiere nor the release of <em>The Princess Bride</em>—both in 1987—could prop up the name as it declined in popularity. The effect makes it look like it’s tumbling off a cliff, instead of regressing to the mean. This graph, including the label, was generated in Python’s <code class="language-plaintext highlighter-rouge">matplotlib</code>.</p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2017/09/figure_1-2.png" alt="" /></p>

<p>After looking at the federal data, I decided to dig into the state-level stuff, to give me a (long-anticipated!) opportunity to generate a choropleth map. Again, I cleaned up the data in Python, and then generated a map using a Javascript library called <code class="language-plaintext highlighter-rouge">&lt;a href="https://d3-geomap.github.io/"&gt;d3-geomap&lt;/a&gt;</code>. For a long time I’ve wanted to get more familiar with its parent library, d3, and this has been a nice opportunity to dip my toe into that.</p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2017/09/wesmap.png" alt="" /></p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="data" /><category term="javascript" /><category term="maps" /><category term="names" /><category term="programming" /><category term="python" /><category term="star trek" /><summary type="html"><![CDATA[One of my goals while at Recurse Center has been to improve my ability to manipulate and visualize data sets. To that end, I’ve been toying around with the Social Security Administration’s baby name dataset, which records the number of babies born with each given name every year, both federally and at the state level. Because I’ve also been watching Star Trek: The Next Generation along with the Treks And The City podcast, I chose to dig into information about the name “Wesley.”]]></summary></entry><entry><title type="html">New bot: @78_sampler, serving up old records</title><link href="https://thisisparker.github.io/dotnet/2017/08/new-bot-78_sampler-serving-up-old-records/" rel="alternate" type="text/html" title="New bot: @78_sampler, serving up old records" /><published>2017-08-11T13:36:49-04:00</published><updated>2017-08-11T13:36:49-04:00</updated><id>https://thisisparker.github.io/dotnet/2017/08/new-bot-78_sampler-serving-up-old-records</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/08/new-bot-78_sampler-serving-up-old-records/"><![CDATA[<p>The Internet Archive hosts an <a href="https://archive.org/details/georgeblood">incredible collection</a> of over 25,000 <a href="http://great78.archive.org/">professionally digitized 78rpm records</a>. The great thing about a catalog that large is that, if you know what you want, you’re likely to find it. On the other hand, if you just want to browse it can be overwhelming and even intimidating. Each item could possibly be a delight, but it’s difficult to even think about individual records in the face of such a huge archive.</p>

<p>In that sense, would-be browsers face similar challenges with the Great 78 Project as they do with the <a href="https://usdawatercolors.nal.usda.gov/pom/home.xhtml">Pomological Watercolor Collection</a>—an archive <a href="https://parkerhiggins.net/tag/pomological-watercolors/">I’ve worked with a lot</a>. Sensing that similarity, I decided to build a tool like <a href="https://twitter.com/pomological">@pomological</a> to help surface individual records.</p>

<p><span class="citation"><a href="https://twitter.com/78_sampler">@78_sampler</a> tweets every two hours with a randomly selected record from the Archive’s collection. It was important to me that the audio fit smoothly and natively into a Twitter timeline, so I decided to render each tune into a video file using the Archive’s still image of the record as the visual. Twitter limits videos to 2:20—exactly 140 seconds, cute—which is shorter than most 78 tunes, so while rendering the video I truncate the clip at that point with a short audio fade at the end.</span></p>

<p>The <a href="https://github.com/thisisparker/78_sampler">code to do all this</a> is a short Python script which I’ve posted online. It relies on ffmpeg to do the video encoding. Crafting ffmpeg commands is famously convoluted, and it’s a little frustrating to format those commands to be called from Python. Maybe that’s something I’ll do differently in the future but, for now, this works and I can dip my cup into the deep Archive well with a little more ease than before.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="bots" /><category term="internet archive" /><category term="music" /><category term="programming" /><category term="python" /><category term="twitter" /><summary type="html"><![CDATA[The Internet Archive hosts an incredible collection of over 25,000 professionally digitized 78rpm records. The great thing about a catalog that large is that, if you know what you want, you’re likely to find it. On the other hand, if you just want to browse it can be overwhelming and even intimidating. Each item could possibly be a delight, but it’s difficult to even think about individual records in the face of such a huge archive.]]></summary></entry><entry><title type="html">He did the monster mosh: automated datamoshing with tweaked GOP lengths</title><link href="https://thisisparker.github.io/dotnet/2017/07/he-did-the-monster-mosh-automated-datamoshing-with-tweaked-gop-lengths/" rel="alternate" type="text/html" title="He did the monster mosh: automated datamoshing with tweaked GOP lengths" /><published>2017-07-21T17:52:32-04:00</published><updated>2017-07-21T17:52:32-04:00</updated><id>https://thisisparker.github.io/dotnet/2017/07/he-did-the-monster-mosh-automated-datamoshing-with-tweaked-gop-lengths</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/07/he-did-the-monster-mosh-automated-datamoshing-with-tweaked-gop-lengths/"><![CDATA[<p>After I posted yesterday about my <a href="https://parkerhiggins.net/2017/07/making-mosh-ups-automated-datamoshing-from-multiple-video-sources/">automated datamoshing experiment</a>, I got a <a href="https://twitter.com/ryanfb/status/888159099413811202">nice message on Twitter from developer and botmaker Ryan Bauman</a> who was able to run my script on his own videos. We talked for a bit about how it could be improved, and I had a major realization that I had to test immediately.</p>

<p>In yesterday’s post I mentioned that the relative prevalence of P-Frames precluded my preferred effect of stills from one video and movement from another. Too much image data was being drawn by the P-Frames for it to really get unrecognizable. I didn’t and still don’t know how to reduce the number of P-Frames per se, but the big realization was I could change the ratio of I-Frames to P-Frames by ratcheting the <a href="https://en.wikipedia.org/wiki/Group_of_pictures">“Group Of Pictures” size</a> way down. That variable determines how often a video includes an I-Frame, and I could set it easily in ffmpeg while re-encoding the source videos.</p>

<p>A normal default GOP size might be 250 frames — which is to say, no more than 10 seconds of video go by without a full I-Frame render. Poking around, I tried changing that number to a few different values to see what works best. Experimentally, a GOP size maximum of 48 frames (once every two seconds) seems to do the trick for two video sources. An excerpt of that video looks like this:</p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="315" loading="lazy" src="https://www.youtube-nocookie.com/embed/TLsT1H7HOs0?rel=0" width="560">  
</iframe>

<p>What are the constraints on the GOP size? Here, as in many other moments of this project, my considerations are very different from most people’s. In most cases, you want I-Frames to happen frequently enough that cutting and seeking through the video can be relatively precise, but rare enough that the filesize can stay low. Since every I-Frame has to contain a full frame of image data, they can be large.</p>

<p>Because I’m swapping I-Frames at the byte level, and truncating or padding each frame to fit, every I-Frame insertion is a potential source of trouble. You can see in the video above, my encoder struggles in certain places. And given that I’m doing substitution, the closer my GOP gets to 1, the more my mosh-up starts to just look like a slideshow.</p>

<p>For single source videos, where I-Frames are likely to be more similar to each other, I was able to use an even shorter GOP length. Here’s a datamoshed version of the Countdown video with a GOP length of 25 frames.</p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="315" loading="lazy" src="https://www.youtube-nocookie.com/embed/u4YJU4mV-7M?rel=0" width="560"></iframe>

<p>So, in conclusion: messing with GOP sizes means a different number of I-Frames which means more opportunities for hijinks in mangling the videos.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="beyonce" /><category term="mash-ups" /><category term="programming" /><category term="python" /><category term="video" /><summary type="html"><![CDATA[After I posted yesterday about my automated datamoshing experiment, I got a nice message on Twitter from developer and botmaker Ryan Bauman who was able to run my script on his own videos. We talked for a bit about how it could be improved, and I had a major realization that I had to test immediately.]]></summary></entry><entry><title type="html">Making mosh-ups: automated datamoshing from multiple video sources</title><link href="https://thisisparker.github.io/dotnet/2017/07/making-mosh-ups-automated-datamoshing-from-multiple-video-sources/" rel="alternate" type="text/html" title="Making mosh-ups: automated datamoshing from multiple video sources" /><published>2017-07-20T15:19:34-04:00</published><updated>2017-07-20T15:19:34-04:00</updated><id>https://thisisparker.github.io/dotnet/2017/07/making-mosh-ups-automated-datamoshing-from-multiple-video-sources</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/07/making-mosh-ups-automated-datamoshing-from-multiple-video-sources/"><![CDATA[<p>Datamoshing is a glitch art technique applied to videos to intentionally create “pixel bleeding” and other digital motion artifacts. It became popular several years ago when it was used in near-simultaneous music videos by <a href="https://www.youtube.com/watch?v=mvqakws0CeU">Chairlift</a> and <a href="https://www.youtube.com/watch?v=wMH0e8kIZtE">Kanye West</a>. In those cases, and in the tutorials and techniques documented since then, the glitches are typically introduced to a single edited video, and done manually in a visual editing program.</p>

<p>My goal for <a href="https://github.com/thisisparker/automosh/blob/master/automosh.py">this project</a> was to use two separate video sources — to make a “mosh-up,” har har — and to completely automate the merger. The holy grail would be to use all the motion from one video over all the stills of another, to make sort of an animated <a href="https://en.wikipedia.org/wiki/Magic_Eye">Magic Eye</a> effect, but without the eye focus requirement. (Side note: it’s <a href="https://sploid.gizmodo.com/this-amazing-magic-eye-music-video-hides-fun-secret-mov-1513555083">possible and awesome</a> to actually create animated Magic Eyes, but that’s beside the point.)</p>

<p>As you’ll see, I fell a little short of that stretch goal, but still managed to make something that looks pretty cool.</p>

<h2 id="moshed-up-vids">Moshed-up vids</h2>

<p><a href="https://github.com/thisisparker/automosh/blob/master/automosh.py">The script I wrote</a> can create two kinds of datamoshes. The first takes a single video as a source and rearranges some key frames to glitch it out. Here’s an example of one such video, glitching up Beyoncé’s incredible <a href="https://www.youtube.com/watch?v=2XY3AvVgDns">Countdown video</a> with itself. I’ve muted the audio in this upload, but as output from the script it still sounds pretty good.</p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="315" loading="lazy" src="https://www.youtube-nocookie.com/embed/a9iNDj0iaug?rel=0" width="560"></iframe>

<p>The second (and more exciting) kind of data moshes takes a certain kind of key frame from one video and replaces the same kind of frame in another video. All of the motion and some of the “re-drawings” of subsequent frames are pulled out of context, creating an effect that is a little surreal and unsettling. It’s not as precise as the pros do with their manual edits, but it also can automatically combine two sources in a way I’ve never seen before. (Here, I used Countdown again, and moshed it together with <a href="https://www.youtube.com/watch?v=pZ12_E5R3qc">Formation</a>.)</p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="315" loading="lazy" src="https://www.youtube-nocookie.com/embed/SARwUp1P7oQ?rel=0" width="560"></iframe>

<p>Again, I’ve muted the audio, but in this case it would normally play back Partition without any noticeable <a href="https://www.youtube.com/watch?v=56qgO0C82vY">flaws</a>.</p>

<h2 id="how-it-works">How it works</h2>

<p>This moshing technique relies on some facts about how the H.264 spec compresses and stores its data. It really is a remarkable standard, and if you’re not familiar it’s absolutely worth reading the tribute that is <a href="https://sidbala.com/h-264-is-magic/">“H.264 is Magic”</a>. The gist is that only a very small portion of frames, dubbed I-Frames, contain all the image data necessary to draw a full screen. The other kinds of frames, P- and B-Frames, have partial screens and “motion” data.</p>

<p>Other popular datamoshing techniques include removing I-Frames altogether or duplicating P-Frames so the same motion is re-applied to an image. In this example, instead, I’m replacing I-Frames with other I-Frames, and I’m doing it simply by copying and pasting the bytes from one into the place of another, truncating or padding out the data so it fits exactly.</p>

<p>The reason I can’t get only the motion from one video and only the “textures” from another is that the P-Frames blend those two types of data together into a single frame. If I could figure out some way to isolate the image data in the frame, or to re-encode a video to consist entirely of I- and B-Frames, I could probably get a wilder effect.</p>

<p>As it stands, the output of this script is a video that <em>plays</em>, but is pretty badly mangled. If you try to play it back in a client that shows you errors, you’ll see a lot of complaints. For compatibility’s sake, I’ve manually transcoded these videos into another format and back.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="beyonce" /><category term="programming" /><category term="python" /><category term="video" /><summary type="html"><![CDATA[Datamoshing is a glitch art technique applied to videos to intentionally create “pixel bleeding” and other digital motion artifacts. It became popular several years ago when it was used in near-simultaneous music videos by Chairlift and Kanye West. In those cases, and in the tutorials and techniques documented since then, the glitches are typically introduced to a single edited video, and done manually in a visual editing program.]]></summary></entry><entry><title type="html">LinkArchiver, a new bot to back up tweeted links</title><link href="https://thisisparker.github.io/dotnet/2017/07/linkarchiver-a-new-bot-to-back-up-tweeted-links/" rel="alternate" type="text/html" title="LinkArchiver, a new bot to back up tweeted links" /><published>2017-07-11T16:10:04-04:00</published><updated>2017-07-11T16:10:04-04:00</updated><id>https://thisisparker.github.io/dotnet/2017/07/linkarchiver-a-new-bot-to-back-up-tweeted-links</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/07/linkarchiver-a-new-bot-to-back-up-tweeted-links/"><![CDATA[<p>Twitter users who want to ensure that the Wayback Machine has stored a copy of the pages they link to can now sign up with <a href="https://twitter.com/linkarchiver"><span class="citation">@LinkArchiver</span></a> to make it happen automatically. <span class="citation">@LinkArchiver</span> is the first project I’ve worked on in my 12-week stay at <a href="https://www.recurse.com/">Recurse Center</a>, where I’m learning to be a better programmer.</p>

<p>The idea for <span class="citation">@LinkArchiver</span> was <a href="https://twitter.com/j4cob/status/883054720260087808">suggested by my friend Jacob</a>. I liked it because it was useful, relatively simple, and combined things I knew (Python wrappers for the Twitter API) with things I didn’t (event-based programming, making a process run constantly in the background, and more). I did not expect it to get as enthusiastic a reaction as it has, but that’s also nice.</p>

<p>The entire bot is <a href="https://github.com/thisisparker/linkarchiver/">one short Python script</a> that uses the Twython library to listen to the <a href="https://dev.twitter.com/streaming/userstreams">Twitter User stream API</a>. This is the first of my Twitter bots that is at all “interactive”—every previous bot used the REST APIs to post, but can not engage with things in their timeline or tweeted at them.</p>

<p>That change meant I had to use a slightly different architecture than I’ve used before. Each of my previous bots were small and self-contained scripts that produced a tweet or two each time they run. That design means I can trigger them with a cron job that runs at regular intervals. By contrast, <span class="citation">@LinkArchiver</span> runs all the time, listening to its timeline and acting when it needs to. It doesn’t have much interactive behavior—when you tweet at it directly, it can reply with a Wayback link, but that’s it—but learning this kind of structure will enable me to do much more interactive bots in the future.</p>

<p>It also required that I figure out how to “daemonize” the script, so that it could run in the background when I wasn’t connected and restart in case it crashed (or when I restart the computer). I found this aspect surprisingly difficult; it seems like a really basic need, but the documentation for how to do this was not especially easy to find. I host my bots on a Digital Ocean box running Ubuntu, so this script is running as a systemd service. The <a href="https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units">Digital Ocean documentation</a> and this <a href="https://www.reddit.com/r/raspberry_pi/comments/4vhofs/creating_a_systemd_daemon_so_you_can_run_a_python/">Reddit tutorial</a> were both very helpful for my figuring it out.</p>

<p>Since launching the bot, I’ve gotten in touch with the folks at the Wayback Machine, and at their request added a custom user-agent. I was worried that the bot would get on their nerves, but they seem to really appreciate it—what a relief. After its first four days online, it’s tracking some 3,400 users and has sent about 25,000 links to the Internet Archive.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="archives" /><category term="bots" /><category term="internet archive" /><category term="programming" /><category term="python" /><category term="twitter" /><summary type="html"><![CDATA[Twitter users who want to ensure that the Wayback Machine has stored a copy of the pages they link to can now sign up with @LinkArchiver to make it happen automatically. @LinkArchiver is the first project I’ve worked on in my 12-week stay at Recurse Center, where I’m learning to be a better programmer.]]></summary></entry><entry><title type="html">New bot: @i_remember_txt, tweeting Joe Brainard’s “I Remember” (1975)</title><link href="https://thisisparker.github.io/dotnet/2017/01/new-bot-i-remember-txt-joe-brainard-i-remember/" rel="alternate" type="text/html" title="New bot: @i_remember_txt, tweeting Joe Brainard’s “I Remember” (1975)" /><published>2017-01-23T23:31:55-05:00</published><updated>2017-01-23T23:31:55-05:00</updated><id>https://thisisparker.github.io/dotnet/2017/01/new-bot-i-remember-txt-joe-brainard-i-remember</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/01/new-bot-i-remember-txt-joe-brainard-i-remember/"><![CDATA[<p>Joe Brainard’s 1975 book “I Remember” is an incredible work of poetry. The New Yorker called it <a href="http://www.newyorker.com/magazine/2008/11/03/the-nancy-book">“his miniaturist memoir-poem,”</a> and Paul Auster’s blurb for the 2001 edition gives a good sense of it:</p>

<blockquote>
  <p><em>I Remember</em> is a masterpiece. One by one, the so-called important books of our time will be forgotten, but Joe Brainard’s modest little gem will endure. In simple, forthright, declarative sentences, he charts the map of the human soul and permanently alters the way we look at the world. <em>I Remember</em> is both uproariously funny and deeply moving. It is also one of the few totally original books I have ever read.</p>
</blockquote>

<p>Those simple declarative sentences—almost all of which begin with “I remember…”—would have been a shock as a book, but today they have the strange familiarity of status updates from your most nostalgic friend.</p>

<p>So when Avery Trufelman asked <a href="https://twitter.com/trufelman/status/820687962266402816">if somebody could make a bot</a> that tweeted his “memories,” I jumped at the chance. And the resulting bot, <a href="https://twitter.com/i_remember_txt">@i_remember_txt</a>, fits in great in between other tweets.</p>

<p><a href="https://twitter.com/i_remember_txt/status/823404900193181696"><img src="https://parkerhiggins.net/wp-content/uploads/2017/01/Screenshot_2017-01-23_20-28-35.png" alt="" /></a></p>

<p>Per usual, <a href="https://github.com/thisisparker/i-remember-txt">the code is online</a> and comments are welcome. It’s pretty straightforward. One thing I did this time which was pretty cool: in the case of memories that were longer than a single tweet, it does <a href="https://twitter.com/i_remember_txt/status/822229699153645568">threaded “tweetstorms”</a> of up to 4-5 in a row.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="avery trufeman" /><category term="bots" /><category term="joe brainard" /><category term="poetry" /><category term="programming" /><category term="python" /><category term="twitter" /><summary type="html"><![CDATA[Joe Brainard’s 1975 book “I Remember” is an incredible work of poetry. The New Yorker called it “his miniaturist memoir-poem,” and Paul Auster’s blurb for the 2001 edition gives a good sense of it:]]></summary></entry><entry><title type="html">Rhyming “who phrases” from New York Times obituary headlines</title><link href="https://thisisparker.github.io/dotnet/2016/10/rhyming-phrases-new-york-times-obituary-headlines/" rel="alternate" type="text/html" title="Rhyming “who phrases” from New York Times obituary headlines" /><published>2016-10-12T02:11:58-04:00</published><updated>2016-10-12T02:11:58-04:00</updated><id>https://thisisparker.github.io/dotnet/2016/10/rhyming-phrases-new-york-times-obituary-headlines</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2016/10/rhyming-phrases-new-york-times-obituary-headlines/"><![CDATA[<p>Many obituary headlines follow a standard formula: “Firstname Lastname, Who You Know From That One Thing, Dies at Age.” It’s a tendency I’ve counted on before when extracting names from obituaries for <a href="https://foiathedead.org/">FOIA The Dead</a>, but tonight it also got me thinking about the “who phrase”: the relative clause that condenses a lifetime of context into a handful of words.</p>

<p>I decided to pull out the “who phrases” from about 1000 headlines over the past year, and using <a href="https://pypi.python.org/pypi/pronouncing"><code class="language-plaintext highlighter-rouge">pronouncing</code></a>, arrange them to rhyme (if not yet to meter). It’s poetry.</p>

<blockquote>
  <p>who made the dallas cowboys cheerleaders a global brand,<br />
who built and ruled world soccer with firm hand,<br />
whose radio show twanged for decades,<br />
who fought racial barriers in building trades,<br />
who delivered in the clutch,<br />
who wrote adolescent novels with a personal touch,<br />
whose b-1 bomber recast the cold war,<br />
who fictionalized medicine’s absurdity and gore,<br />
who promoted n.w.a. and gangsta rap,<br />
who bridged racial gap,<br />
who chronicled his cancer fight,<br />
who set ‘the wicker man’ cult alight,<br />
who embraced gonzo journalism,<br />
who lost his prime to racism,<br />
who led sicilian mafia clan,<br />
who took aim at iran,<br />
who shaped venture capitalism,<br />
who shifted to optimism,<br />
who wrote of colonialism and racism,<br />
who preached pacifism,<br />
who won a round-the-world race,<br />
who quit in pentagon papers case,<br />
who wrote of madness and isolation,<br />
who helped turn wlir into a radio destination,<br />
who helped pave way for head start,<br />
who elevated blown glass to fine art,<br />
whose furniture evoked sensuality,<br />
who examined puerto rican identity,<br />
who saw literary criticism as art,<br />
who gave the rolling stones their start,<br />
whose bleak fiction won the booker prize,<br />
who shaped foreign ties,<br />
who put the @ sign in email,<br />
who shaped geometries on a bold scale.</p>
</blockquote>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="new york times" /><category term="obituary" /><category term="poetry" /><category term="programming" /><category term="python" /><summary type="html"><![CDATA[Many obituary headlines follow a standard formula: “Firstname Lastname, Who You Know From That One Thing, Dies at Age.” It’s a tendency I’ve counted on before when extracting names from obituaries for FOIA The Dead, but tonight it also got me thinking about the “who phrase”: the relative clause that condenses a lifetime of context into a handful of words.]]></summary></entry></feed>