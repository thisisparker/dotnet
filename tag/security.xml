<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/dotnet/tag/security.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/dotnet/" rel="alternate" type="text/html" /><updated>2022-09-18T22:31:32-04:00</updated><id>http://localhost:4000/dotnet/tag/security.xml</id><title type="html">parker higgins dot net</title><subtitle></subtitle><author><name>Parker Higgins</name></author><entry><title type="html">Amazon backdoor exposed wishlist mailing addresses</title><link href="http://localhost:4000/dotnet/2016/01/earlier-amazon-backdoor-exposed-wishlist-mailing-addresses/" rel="alternate" type="text/html" title="Amazon backdoor exposed wishlist mailing addresses" /><published>2016-01-24T23:15:22-05:00</published><updated>2016-01-24T23:15:22-05:00</updated><id>http://localhost:4000/dotnet/2016/01/earlier-amazon-backdoor-exposed-wishlist-mailing-addresses</id><content type="html" xml:base="http://localhost:4000/dotnet/2016/01/earlier-amazon-backdoor-exposed-wishlist-mailing-addresses/"><![CDATA[<p>There’s an article circulating right now about how <a href="https://medium.com/@espringe/amazon-s-customer-service-backdoor-be375b3428c4#.hqxfxuajw">Amazon customer service can be exploited to reveal targeted mailing addresses</a>. I discovered and reported a similar vulnerability in December of 2014, which was reported to me as fixed in May of 2015. I haven’t publicly documented that process until now.</p>

<p>The vulnerability I discovered relates to <a href="http://www.amazon.com/gp/registry/search">Amazon wishlists</a>. Users can associate wishlists with a private address, so that people can buy and ship them gifts without having the recipient’s private information. That address should be kept confidential throughout the entire process, but I found that third party shippers—routinely used for Amazon sites outside of the United States—would sometimes include it in confirmation emails.</p>

<p>In particular: I used Amazon.ca to send a book to a friend, and Canada Post delivered her full address to me in an email. In this exchange, Amazon’s confirmation email properly showed my friend’s address as redacted, but Canada Post revealed it in its entirety.</p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2016/01/Screenshot_2016-01-24_19-57-19.png" alt="Amazon confirmation" /></p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2016/01/canada-post-confirmation.png" alt="" /></p>

<p>That would be unacceptable in any circumstance. But it’s all the worse because some of the people who use Amazon wishlists are especially vulnerable to targeted harassment. The service is popular, for instance, <a href="http://www.dailydot.com/lifestyle/amazon-sex-worker-wish-lists/">among camgirls and sex workers accepting gifts</a>. I’ve also seen wishlists from Twitter microcelebrities, who get occasional threats and unwanted creepy overtures, as well as wishlists from women who are trying to get some support after leaving an abusive domestic situation. For many of these people, a revealed address can be devastating.</p>

<p>I contacted <a href="http://www.amazon.com/gp/help/customer/display.html/ref=hp_left_sib?ie=UTF8&amp;nodeId=201182150">Amazon Security</a> via email, ((They make a PGP key available, but <a href="http://www.amazon.com/gp/help/customer/display.html?nodeId=200724850">only distribute it over unauthenticated HTTP</a>. All the more reason Amazon should switch to entirely HTTPS.)) and got a confirmation number and a response from a human that it had been assigned to somebody. The fix, introduced in May, seems to simply removed the second confirmation email direct from Canada Post.</p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2016/01/Screenshot_2016-01-24_20-05-52.png" alt="My email to Amazon Security" /></p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2016/01/Screenshot_2016-01-24_20-06-23.png" alt="Amazon Security fix" /></p>

<p>Although the five month window to fix this situation seemed too long to me, I didn’t want to go public until it had been addressed. An attacker who knew about this vulnerability could easily exploit it for the cost of the cheapest item on a particular wishlist, and the only fix a user could make was removing their address entirely.</p>

<p>Given that particular combination—easy, cheap exploitation, and no alternative path to security—it seemed irresponsible in this case to disclose the problem publicly. Others may disagree.</p>

<p>This isn’t the first time wishlists have inadvertently leaked address data—it happened <a href="http://wishlistexposed.blogspot.com/">at least once before in 2011</a>. Nor do I know for sure that the fix has been applied worldwide, as I only tested in Canada. Unfortunately, <a href="https://ssd.eff.org/en/module/introduction-threat-modeling">for people who could face threats if their address were revealed</a>, Amazon seems like a dangerous service to share it with.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="amazon" /><category term="privacy" /><category term="security" /><summary type="html"><![CDATA[There’s an article circulating right now about how Amazon customer service can be exploited to reveal targeted mailing addresses. I discovered and reported a similar vulnerability in December of 2014, which was reported to me as fixed in May of 2015. I haven’t publicly documented that process until now.]]></summary></entry><entry><title type="html">Limiting Javascript to secure origins in Firefox</title><link href="http://localhost:4000/dotnet/2015/09/limiting-javascript-to-secure-origins-in-firefox/" rel="alternate" type="text/html" title="Limiting Javascript to secure origins in Firefox" /><published>2015-09-28T23:08:39-04:00</published><updated>2015-09-28T23:08:39-04:00</updated><id>http://localhost:4000/dotnet/2015/09/limiting-javascript-to-secure-origins-in-firefox</id><content type="html" xml:base="http://localhost:4000/dotnet/2015/09/limiting-javascript-to-secure-origins-in-firefox/"><![CDATA[<p>I’m a Firefox user, but I was very interested to read Chris Palmer’s <a href="https://noncombatant.org/2014/03/11/privacy-and-security-settings-in-chrome/">guide to privacy and security settings in Chrome</a>. One thing he did that really intrigued me was enabling Javascript only on secure sites. It ends up being a pretty good default not just because it prevents attacks that rely on Javascript injection—like the ads that <a href="http://arstechnica.com/tech-policy/2014/09/why-comcasts-javascript-ad-injections-threaten-security-net-neutrality/">Comcast</a> and <a href="http://webpolicy.org/2015/08/25/att-hotspots-now-with-advertising-injection/">AT&amp;T</a> have inserted into pages accessed on their hotspots, or the <a href="https://www.eff.org/deeplinks/2015/04/china-uses-unencrypted-websites-to-hijack-browsers-in-github-attack">massive man-on-the-side attack</a> the government of China apparently conducted against Github—but also because a site going through the effort to authenticate itself is also a reasonable proxy for the kind of stuff I’d allow anyway.</p>

<p>As far as I can tell, on Firefox that means installing <a href="https://noscript.net/">NoScript, a powerful extension</a> that I’d previously disabled because manually turning on Javascript where I needed it was too much of a hassle. After a few hours of browsing with these settings, it seems to strike the right balance: not exactly <em>no</em> fiddling with permissions, but greatly reduced manual intervention with a lot of unnecessary scripts getting blocked.</p>

<p>The option is in NoScript’s preferences, under <code class="language-plaintext highlighter-rouge">Options &gt; Advanced &gt; HTTPS &gt; Permissions</code>. As long as the global block is on (which it is by default), I found that setting the drop-down menu, “Forbid active web content unless it comes from a secure HTTPS connection” actually works best when set to “Never”—or if you’re a frequent Tor user, to “When using a proxy”. ((This setting is pretty counter-intuitive to me, but if it is set to “Always” I experienced some funny interactions with manual permission changes.)) Then the checkbox below, “Allow HTTPS scripts globally on HTTPS documents”, should be checked.</p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2015/09/Screenshot_2015-09-28_20-00-40.png" alt="Screenshot_2015-09-28_20-00-40" /></p>

<p>Of course, this isn’t a perfect guarantee of privacy or security. If you don’t trust the Javascript being served from the authenticated site—because the site operators may be malicious or just incompetent—then this technique won’t help. But it does make browsing much faster across much of the web, and preserve the rich interactivity you’re used to on pages your browser trusts.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="firefox" /><category term="javascript" /><category term="security" /><summary type="html"><![CDATA[I’m a Firefox user, but I was very interested to read Chris Palmer’s guide to privacy and security settings in Chrome. One thing he did that really intrigued me was enabling Javascript only on secure sites. It ends up being a pretty good default not just because it prevents attacks that rely on Javascript injection—like the ads that Comcast and AT&amp;T have inserted into pages accessed on their hotspots, or the massive man-on-the-side attack the government of China apparently conducted against Github—but also because a site going through the effort to authenticate itself is also a reasonable proxy for the kind of stuff I’d allow anyway.]]></summary></entry><entry><title type="html">An email signature to encourage encryption use</title><link href="http://localhost:4000/dotnet/2014/08/email-signature-nudge-encryption-use/" rel="alternate" type="text/html" title="An email signature to encourage encryption use" /><published>2014-08-10T20:38:38-04:00</published><updated>2014-08-10T20:38:38-04:00</updated><id>http://localhost:4000/dotnet/2014/08/email-signature-nudge-encryption-use</id><content type="html" xml:base="http://localhost:4000/dotnet/2014/08/email-signature-nudge-encryption-use/"><![CDATA[<p><img src="http://imgs.xkcd.com/comics/pgp.png" alt="" />A great way to encourage more ubiquitous email encryption is to let people you’re emailing know that you’re equipped to use it, and that they can be too.</p>

<p>Some people use PGP signatures for that purpose, but inline signatures can be off-putting to people who don’t know what they are, and attachments can be similarly confusing. (Not to mention that, <a href="https://xkcd.com/1181/">as XKCD notes</a>, the security benefits are pretty slim.)</p>

<p>A one-line addition to an email signature is a good compromise. I propose the following:</p>

<blockquote>
  <p>I prefer to use encrypted email. My public key fingerprint is 4FF3 AA1B D29E 1638 32DE C765 9433 5F88 9A36 7709. Learn how to encrypt your email with <a href="https://emailselfdefense.fsf.org/en/">the Email Self Defense guide</a>.</p>
</blockquote>

<p>In my case, because I’ve got my key available on an HTTPS site, I’d probably <a href="https://www.eff.org/files/2013/11/03/parkerkey.txt">link to it directly</a> as well.</p>

<p>This system isn’t perfect, and in particular is not a very secure way to distribute your fingerprint. But it could be a good nudge to people who might be considering learning about email encryption while flagging you as somebody who might be able to help, and especially if you post to publicly archived mailing lists, it’s a way of getting your fingerprint tied to your emails in lots of places.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="crypto" /><category term="encryption" /><category term="pgp" /><category term="privacy" /><category term="security" /><summary type="html"><![CDATA[A great way to encourage more ubiquitous email encryption is to let people you’re emailing know that you’re equipped to use it, and that they can be too.]]></summary></entry><entry><title type="html">Guide to security guides</title><link href="http://localhost:4000/dotnet/2014/03/guide-to-security-guides/" rel="alternate" type="text/html" title="Guide to security guides" /><published>2014-03-17T01:49:59-04:00</published><updated>2014-03-17T01:49:59-04:00</updated><id>http://localhost:4000/dotnet/2014/03/guide-to-security-guides</id><content type="html" xml:base="http://localhost:4000/dotnet/2014/03/guide-to-security-guides/"><![CDATA[<p>Here are some resources I’ve found very useful for getting through the many communication options that are presented as secure.</p>

<ul>
  <li>“<a href="https://missingm.co/2014/02/fighting-dishfire-the-state-of-mobile-cross-platform-encrypted-messaging/">The State of Mobile, Cross-Platform, Encrypted Messaging</a>” – This is all about mobile apps for end-to-end crypto. My money’s on TextSecure once it’s out for iPhone. Since the major version upgrade it’s been one of my favorite examples of workable crypto software.</li>
  <li>“<a href="https://github.com/OpenTechFund/secure-email">Next-generation secure email</a>” – Who knows what’s coming next for email? We need something that allows text and media to be transmitted in an end-to-end encrypted asynchronous (but fast) channel. This guide breaks down the various options well.</li>
  <li>“<a href="http://evanhahn.com/2fa/">Two Factor Authentication List</a>” – This one’s a little different, in that it aims to be an exhaustive list of all the places the 2FA are available for users. It accepts pull requests, so if something’s missing, add it! There’s also <a href="http://twofactorauth.org/">a second list</a>, which breaks down the services by category and how the second factor is delivered, but it’s not quite as comprehensive yet.</li>
</ul>

<p>What am I missing? Let me know and I’ll add it in.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="crypto" /><category term="email" /><category term="security" /><category term="textsecure" /><category term="two factor authentication" /><summary type="html"><![CDATA[Here are some resources I’ve found very useful for getting through the many communication options that are presented as secure.]]></summary></entry><entry><title type="html">It wasn’t Yahoo that was hacked</title><link href="http://localhost:4000/dotnet/2014/02/it-wasnt-yahoo-that-was-hacked/" rel="alternate" type="text/html" title="It wasn’t Yahoo that was hacked" /><published>2014-02-03T03:52:39-05:00</published><updated>2014-02-03T03:52:39-05:00</updated><id>http://localhost:4000/dotnet/2014/02/it-wasnt-yahoo-that-was-hacked</id><content type="html" xml:base="http://localhost:4000/dotnet/2014/02/it-wasnt-yahoo-that-was-hacked/"><![CDATA[<p>I’ve been disappointed to see a lot of journalists get a recent story about security breaches and Yahoo Mail wrong. In particular, I worry that this kind of misleading reporting will contribute to worse security practices for both the companies that users trust with their data, and the users themselves.</p>

<p>First, here’s what happened: Yahoo <a href="http://yahoo.tumblr.com/post/75083532312/important-security-update-for-yahoo-mail-users">reported on its Tumblr</a> that it had detected “a coordinated effort”—basically, an attack—by somebody trying to gain access to user accounts. Yahoo deserves some credit here for reporting that information, and also for taking the good next steps of resetting passwords of affected users and “implement[ing] additional measures to block attacks.”</p>

<p>This is not an attack on Yahoo. It’s the predictable result of a leak of <em>somebody else’s</em> database. Let’s call the origin of that database Company X. Company X’s database contains both user email addresses and passwords to log into Company X’s site. But if Company X users had the same password to log in to both their email account and Company X’s site, it’s trivial to take the leaked information and try to log into email accounts with it.</p>

<p>That’s what it sounds like happened in this case. Yahoo detected somebody using this leaked database to try to get into many different user accounts and proactively changed passwords to mitigate the risk for people who reuse password.</p>

<p>But the press reported it instead as if Yahoo had screwed up. Slate’s barely-accurate headline is “<a href="http://www.slate.com/blogs/the_slatest/2014/01/30/yahoo_reports_some_email_usernames_and_passwords_stolen_in_cyberattack.html">Yahoo Email Usernames and Passwords Stolen in Cyberattack.</a>” LA Times says <a href="http://www.latimes.com/business/technology/la-fi-tn-yahoo-mail-breach-number-users-not-disclosed-20140130,0,3294421.story">Yahoo “fell victim” to an attack</a>; Washington Post’s headline was “<a href="http://www.washingtonpost.com/business/technology/yahoo-mail-hacked-what-to-do-if-youve-been-affected/2014/01/31/2857ef8a-8a7d-11e3-833c-33098f9e5267_story.html">Yahoo mail hacked</a>” and goes on to give Yahoo-specific security tips.</p>

<p>That’s where the real danger is: misunderstanding this kind of breach as the result of bad security by <em>Yahoo</em>, and not bad security by <em>users</em>. The right way to mitigate this problem is to never reuse passwords, and certainly never to reuse your email account password. Note that this entire attack fails completely if users’ Company X passwords are different from their Yahoo Mail passwords. The best way to use good and unique passwords is to use a password safe like <a href="https://www.keepassx.org/">KeePass X</a> or <a href="https://lastpass.com/">LastPass</a> and have that program generate a new one for each site.</p>

<p>This is good advice everywhere, but absolutely critical stop-reading-this-blog-post-and-do-it-now advice for email accounts. Email addresses are both uniquely vulnerable targets and valuable assets for attackers. A leaked database from some random site won’t include information about your credentials on other websites <em>except</em> your email. And compromising an email account can get an attacker master keys into other accounts. They can search for banking info, for example, and have your super-secret bank password reset with a “Forgot my password?” email reset option.</p>

<p>Given those heightened risks, you want your email provider to be especially vigilant. When they detect any kind of attack, you want them to take action. I worry that if the press reports this kind of sensible reaction as if it were a screw-up, it will discourage other companies from following suit.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="passwords" /><category term="security" /><category term="yahoo" /><summary type="html"><![CDATA[I’ve been disappointed to see a lot of journalists get a recent story about security breaches and Yahoo Mail wrong. In particular, I worry that this kind of misleading reporting will contribute to worse security practices for both the companies that users trust with their data, and the users themselves.]]></summary></entry><entry><title type="html">Square’s security anti-patterns</title><link href="http://localhost:4000/dotnet/2012/10/squares-security-anti-patterns/" rel="alternate" type="text/html" title="Square’s security anti-patterns" /><published>2012-10-08T03:38:13-04:00</published><updated>2012-10-08T03:38:13-04:00</updated><id>http://localhost:4000/dotnet/2012/10/squares-security-anti-patterns</id><content type="html" xml:base="http://localhost:4000/dotnet/2012/10/squares-security-anti-patterns/"><![CDATA[<p><a href="https://squareup.com/">Square</a> dongles really truly make processing credit cards not just easier, but possible for all sorts of groups that didn’t have access before: I’ve bought from bands selling merchandise, taxi drivers, food cart operators, and more. I’m worried, though, that Square also makes credit card fraud easier by teaching credit card users security <a href="https://en.wikipedia.org/wiki/Anti-pattern">anti-patterns</a>.</p>

<p><a href="https://parkerhiggins.net/wp-content/uploads/2012/10/square-reader.jpg"><img src="https://parkerhiggins.net/wp-content/uploads/2012/10/square-reader.jpg" alt="" title="Square reader on an iPad" /></a></p>

<p>In practice, using a Square reader is pretty similar to using any other credit card reader. At the money part of the transaction, you hand your card to the vendor or swipe it yourself through a little dongle hooked up to the headphone jack of an iOS or Android device. Then you enter your email, if you want a receipt sent to you, and sign with your finger on the screen.</p>

<p>That’s the standard description. But it could also be described as handing your credit card to a stranger with a <a href="https://en.wikipedia.org/wiki/Credit_card_fraud#Skimming">skimmer</a>, and then giving him your signature. That’s what makes it an anti-pattern: it has become commonly used, but is counter-productive to security efforts.</p>

<p>In the overwhelming majority of cases, both parties are honest, and nothing goes wrong. But it’s easy to imagine a few ways it could go wrong. For one thing, if the vendor is dishonest, he could intentionally record the data and use it or sell it later. That’s how a standard skimmer works, and the same problem exists every time you hand your card to the waiter at a restaurant.</p>

<p>Even if both parties are honest though, they are trusting the integrity of the software. I haven’t heard of it yet, but again it’s not too hard to imagine malware that attacks exploits in, say, Android or iOS themselves, and surreptitiously records and sends the card data to the attacker. Such malware could target a wide swath of devices and transactions, and would be more difficult to pinpoint as the source of the data leak.</p>

<p>Unlike the first scenario, this one is exacerbated in the Square era. Previously, <a href="https://www.networkworld.com/news/2011/030311-cybercriminals-targeting-point-of-sale.html?page=1">malware targeting point-of-sale devices had to be very specialized</a>. Now, though, point-of-sale devices are general purpose computers and vulnerable to commonly known exploits. And in many scenarios, they’re used for other purposes, too, exposing them to more attack vectors.</p>

<p>Really, though, the problem here is not with Square, but with the structure of credit card security. Our card numbers are a secret, and the only information required to carry out many transactions, but we also entrust them with every stranger we make a payment to.</p>

<p>We used to address this issue by an ad hoc security-by-point-of-sale system. If somebody had an official point-of-sale system, our intuition said they were trustworthy, and that was pretty robust. But it’s failing the same way that, say, <a href="https://www.schneier.com/blog/archives/2007/10/security_by_let.html">security-by-letterhead</a> has failed. Technology has made attacks we’ve dismissed as prohibitively difficult much easier, and we need to change our behavior to reflect that.</p>

<hr />

<p>photo: <a href="http://www.flickr.com/photos/cdharrison/4991885743/in/photostream/">The infamous Square card reader</a>. used under <a href="http://creativecommons.org/licenses/by/2.0/deed.en">CC BY</a></p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="money" /><category term="payment" /><category term="security" /><category term="square" /><summary type="html"><![CDATA[Square dongles really truly make processing credit cards not just easier, but possible for all sorts of groups that didn’t have access before: I’ve bought from bands selling merchandise, taxi drivers, food cart operators, and more. I’m worried, though, that Square also makes credit card fraud easier by teaching credit card users security anti-patterns.]]></summary></entry><entry><title type="html">Questioning copyright’s trade-off</title><link href="http://localhost:4000/dotnet/2012/08/questioning-copyrights-trade-off/" rel="alternate" type="text/html" title="Questioning copyright’s trade-off" /><published>2012-08-02T20:25:53-04:00</published><updated>2012-08-02T20:25:53-04:00</updated><id>http://localhost:4000/dotnet/2012/08/questioning-copyrights-trade-off</id><content type="html" xml:base="http://localhost:4000/dotnet/2012/08/questioning-copyrights-trade-off/"><![CDATA[<p><em>This post is <a href="https://www.eff.org/deeplinks/2012/08/questioning-copyrights-trade-off">cross-posted from the EFF Deeplinks blog</a>.</em></p>

<p>The idea behind copyright is simple — it is supposed to be a balance in the service of the public interest. There’s a trade-off: for accepting a restriction on certain speech, the public benefits from the production of more new creative works each year. That delicate equation is complicated by many factors, and the right policy should find the balance of copyright scope and duration, limitations and exceptions like fair use, and the appropriate remedies in case of infringement.</p>

<p>But in fact, copyright policies almost universally lack the serious cost-benefit analysis that must precede any evidence-based proposal. And indeed, while the unintended costs are clear to anybody who has observed <a href="https://www.eff.org/deeplinks/2011/12/blacklist-bills-ripe-abuse">abuse of, say, the DMCA takedown system</a>, the evidence that these policies create incentives — or even prevent harm — is less forthcoming.</p>

<p>Last week <a href="https://twitter.com/normative">Julian Sanchez</a> of the Cato Institute posted <a href="http://www.cato-at-liberty.org/talking-about-trade-offs-between-liberty-and-security-begs-the-question/">a thought-provoking piece that questions the similar calculation at the core of national security rhetoric</a>. In the area of security, he asks, are we actually getting a “trade-off” for all the costs we incur to the country’s budget and our personal liberty? Sanchez convincingly argues that we haven’t been working towards a balance between those two ideas at all. Liberty is consistently discarded in the name of “security,” and the resulting policies don’t actually make us safer. A dialogue that focuses only on striking a balance between these two ideas fails to address more fundamental questions about our policy.</p>

<p>So, too, with copyright. The right copyright policy should serve the constitutional purpose of promoting “<a href="https://en.wikipedia.org/wiki/Copyright_Clause">the progress of science and the useful arts</a>” while respecting the ideals of the First Amendment. The need for such a balance is well recognized from all corners of the copyright discussion. In a post about the misguided Supreme Court opinion in <em>Golan v. Holder</em> this January, for example, EFF referred to the “<a href="https://www.eff.org/deeplinks/2012/01/supreme-court-gets-it-wrong-golan-v-holder-public-domain-mourns">traditional copyright balance between public and private interests</a>“; and while EFF doesn’t always see eye-to-eye on copyright issues with content lobby groups like the Recording Industry Association of America (RIAA), its chief executive Cary Sherman has also described <a href="https://www.riaa.com/blog.php?content_selector=riaa-news-blog&amp;blog_selector=Viacom_YouTube&amp;blog_type=&amp;news_month_filter=6&amp;news_year_filter=2010">“the careful balance struck within” copyright law</a>.</p>

<p>It makes sense, then, that one typical response to bad copyright policy developments — and there are many — is to say that those developments skew this balance the wrong way, favoring the incentives and rewards for rightsholders more than is necessary to maximize creative production. But that approach overlooks the fact that many of the worst copyright proposals, like those that come out of content lobbying groups like the RIAA and the Motion Picture Association of America (MPAA) do worse than a skewed balance. Rather, they fail to strike any kind of balance at all, curtailing speech and fundamental online rights without a corresponding increase in the incentive to create new works.</p>

<p>By and large, in the legislature, in the courtroom, in the White House, and in the backroom negotiations for international treaties, balance does not seem to be the real goal. This year’s protests against SOPA and ACTA were certainly historic demonstrations of online activism, but those proposed laws were just the latest in a long line. Even as <a href="https://www.eff.org/deeplinks/2012/07/acta-victory-europe-and-what-lies-ahead">ACTA met defeat in Europe</a>, the <a href="https://www.eff.org/deeplinks/2012/07/21st-century-agreement-is-really-best-way">Trans-Pacific Partnership Agreement (TPP) was being negotiated</a> with industry representatives behind closed doors, with guardians of the public interest on the outside. SOPA was an <a href="https://www.eff.org/deeplinks/2011/10/sopa-hollywood-finally-gets-chance-break-internet/">egregious and over-the-top wishlist of Hollywood demands</a>, but it was hardly new: <a href="https://www.eff.org/deeplinks/2011/05/protect-ip-act-coica-redux">its Senate counterpart, PIPA</a>, was a re-write of <a href="https://www.eff.org/deeplinks/2010/09/censorship-internet-takes-center-stage-online">a bill from two years earlier called COICA</a>. And Congress has passed dozens of other one-sided copyright laws over the last thirty years.</p>

<p>If it were simply a matter of striking the wrong balance, SOPA’s cost in terms of <a href="https://www.eff.org/deeplinks/2011/11/proposed-copyright-bill-threatens-whistleblowing-and-human-rights">threatening human rights</a>, <a href="https://www.eff.org/deeplinks/2012/01/how-pipa-and-sopa-violate-white-house-principles-supporting-free-speech">curtailing freedom of speech</a>, and <a href="https://www.eff.org/deeplinks/2012/01/truth-about-economics-behind-blacklist-bills">damaging the economy</a> would have to be offset by gains to the content lobby backing the bill. It wouldn’t be the <em>right</em> trade-off, but it would make sense in the context of a balance. In reality, though, the benefits for the content lobby simply weren’t there. In January, Sanchez himself <a href="http://www.cato-at-liberty.org/how-copyright-industries-con-congress/">calculated that the size of the foreign “pirate” movie market targeted at Americans</a> — the kind of activity SOPA was written to address — was orders of magnitude below the MPAA claims. And for their part, the RIAA recently revealed in <a href="https://torrentfreak.com/leaked-riaa-report-sopapipa-ineffective-tool-against-music-piracy-120727/">a leaked report from April</a> that despite its public rhetoric, it felt SOPA was “not likely to have been [an] effective tool for music” even if it had passed.</p>

<p>Similarly, when the 1998 Copyright Term Extension Act — sometimes called the “Mickey Mouse Protection Act” because it kept the world’s most famous rodent out of the public domain — was challenged in the Supreme Court, <a href="https://cyber.law.harvard.edu/openlaw/eldredvashcroft/supct/amici/economists.pdf">some of the world’s leading economists lined up in a brief</a> [pdf] to question the premise that the public benefited from retroactive term extension at all. Once again, the costs to the public are clear: we all suffer from a poorer public domain with no clear gains in return. Worse, these examples are the rule and not the exception. Many elements of policy today — from <a href="https://www.eff.org/wp/unintended-consequences-under-dmca/">DMCA’s problematic section 1201</a> to the unconstitutional <a href="https://www.eff.org/deeplinks/2011/02/ice-seizures-raising-new-speech-concerns">ICE seizures of websites</a> — and dozens more failed proposals — like the “<a href="http://news.cnet.com/2100-1023-946316.html?tag=politech">Hollywood Hacking bill</a>” or the <a href="https://www.eff.org/issues/broadcast-flag">broadcast flag</a> — fit this pattern.</p>

<p>Compared to the trade-off of security and liberty, the question at the heart of copyright policy is an easy one: How do we optimize the incentive to create new works while minimizing the cost to our freedom of speech and ability to innovate? Unfortunately, sane policy developments that work toward this end are all too rare.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="copyright" /><category term="EFF" /><category term="julian sanchez" /><category term="policy" /><category term="security" /><summary type="html"><![CDATA[This post is cross-posted from the EFF Deeplinks blog.]]></summary></entry></feed>