<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/dotnet/tag/beyonce.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/dotnet/" rel="alternate" type="text/html" /><updated>2022-09-18T18:13:34-04:00</updated><id>http://localhost:4000/dotnet/tag/beyonce.xml</id><title type="html">parker higgins dot net</title><subtitle></subtitle><author><name>Parker Higgins</name></author><entry><title type="html">He did the monster mosh: automated datamoshing with tweaked GOP lengths</title><link href="http://localhost:4000/dotnet/2017/07/he-did-the-monster-mosh-automated-datamoshing-with-tweaked-gop-lengths/" rel="alternate" type="text/html" title="He did the monster mosh: automated datamoshing with tweaked GOP lengths" /><published>2017-07-21T17:52:32-04:00</published><updated>2017-07-21T17:52:32-04:00</updated><id>http://localhost:4000/dotnet/2017/07/he-did-the-monster-mosh-automated-datamoshing-with-tweaked-gop-lengths</id><content type="html" xml:base="http://localhost:4000/dotnet/2017/07/he-did-the-monster-mosh-automated-datamoshing-with-tweaked-gop-lengths/"><![CDATA[<p>After I posted yesterday about my <a href="https://parkerhiggins.net/2017/07/making-mosh-ups-automated-datamoshing-from-multiple-video-sources/">automated datamoshing experiment</a>, I got a <a href="https://twitter.com/ryanfb/status/888159099413811202">nice message on Twitter from developer and botmaker Ryan Bauman</a> who was able to run my script on his own videos. We talked for a bit about how it could be improved, and I had a major realization that I had to test immediately.</p>

<p>In yesterday’s post I mentioned that the relative prevalence of P-Frames precluded my preferred effect of stills from one video and movement from another. Too much image data was being drawn by the P-Frames for it to really get unrecognizable. I didn’t and still don’t know how to reduce the number of P-Frames per se, but the big realization was I could change the ratio of I-Frames to P-Frames by ratcheting the <a href="https://en.wikipedia.org/wiki/Group_of_pictures">“Group Of Pictures” size</a> way down. That variable determines how often a video includes an I-Frame, and I could set it easily in ffmpeg while re-encoding the source videos.</p>

<p>A normal default GOP size might be 250 frames — which is to say, no more than 10 seconds of video go by without a full I-Frame render. Poking around, I tried changing that number to a few different values to see what works best. Experimentally, a GOP size maximum of 48 frames (once every two seconds) seems to do the trick for two video sources. An excerpt of that video looks like this:</p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="315" loading="lazy" src="https://www.youtube-nocookie.com/embed/TLsT1H7HOs0?rel=0" width="560">  
</iframe>

<p>What are the constraints on the GOP size? Here, as in many other moments of this project, my considerations are very different from most people’s. In most cases, you want I-Frames to happen frequently enough that cutting and seeking through the video can be relatively precise, but rare enough that the filesize can stay low. Since every I-Frame has to contain a full frame of image data, they can be large.</p>

<p>Because I’m swapping I-Frames at the byte level, and truncating or padding each frame to fit, every I-Frame insertion is a potential source of trouble. You can see in the video above, my encoder struggles in certain places. And given that I’m doing substitution, the closer my GOP gets to 1, the more my mosh-up starts to just look like a slideshow.</p>

<p>For single source videos, where I-Frames are likely to be more similar to each other, I was able to use an even shorter GOP length. Here’s a datamoshed version of the Countdown video with a GOP length of 25 frames.</p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="315" loading="lazy" src="https://www.youtube-nocookie.com/embed/u4YJU4mV-7M?rel=0" width="560"></iframe>

<p>So, in conclusion: messing with GOP sizes means a different number of I-Frames which means more opportunities for hijinks in mangling the videos.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="beyonce" /><category term="mash-ups" /><category term="programming" /><category term="python" /><category term="video" /><summary type="html"><![CDATA[After I posted yesterday about my automated datamoshing experiment, I got a nice message on Twitter from developer and botmaker Ryan Bauman who was able to run my script on his own videos. We talked for a bit about how it could be improved, and I had a major realization that I had to test immediately.]]></summary></entry><entry><title type="html">Making mosh-ups: automated datamoshing from multiple video sources</title><link href="http://localhost:4000/dotnet/2017/07/making-mosh-ups-automated-datamoshing-from-multiple-video-sources/" rel="alternate" type="text/html" title="Making mosh-ups: automated datamoshing from multiple video sources" /><published>2017-07-20T15:19:34-04:00</published><updated>2017-07-20T15:19:34-04:00</updated><id>http://localhost:4000/dotnet/2017/07/making-mosh-ups-automated-datamoshing-from-multiple-video-sources</id><content type="html" xml:base="http://localhost:4000/dotnet/2017/07/making-mosh-ups-automated-datamoshing-from-multiple-video-sources/"><![CDATA[<p>Datamoshing is a glitch art technique applied to videos to intentionally create “pixel bleeding” and other digital motion artifacts. It became popular several years ago when it was used in near-simultaneous music videos by <a href="https://www.youtube.com/watch?v=mvqakws0CeU">Chairlift</a> and <a href="https://www.youtube.com/watch?v=wMH0e8kIZtE">Kanye West</a>. In those cases, and in the tutorials and techniques documented since then, the glitches are typically introduced to a single edited video, and done manually in a visual editing program.</p>

<p>My goal for <a href="https://github.com/thisisparker/automosh/blob/master/automosh.py">this project</a> was to use two separate video sources — to make a “mosh-up,” har har — and to completely automate the merger. The holy grail would be to use all the motion from one video over all the stills of another, to make sort of an animated <a href="https://en.wikipedia.org/wiki/Magic_Eye">Magic Eye</a> effect, but without the eye focus requirement. (Side note: it’s <a href="https://sploid.gizmodo.com/this-amazing-magic-eye-music-video-hides-fun-secret-mov-1513555083">possible and awesome</a> to actually create animated Magic Eyes, but that’s beside the point.)</p>

<p>As you’ll see, I fell a little short of that stretch goal, but still managed to make something that looks pretty cool.</p>

<h2 id="moshed-up-vids">Moshed-up vids</h2>

<p><a href="https://github.com/thisisparker/automosh/blob/master/automosh.py">The script I wrote</a> can create two kinds of datamoshes. The first takes a single video as a source and rearranges some key frames to glitch it out. Here’s an example of one such video, glitching up Beyoncé’s incredible <a href="https://www.youtube.com/watch?v=2XY3AvVgDns">Countdown video</a> with itself. I’ve muted the audio in this upload, but as output from the script it still sounds pretty good.</p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="315" loading="lazy" src="https://www.youtube-nocookie.com/embed/a9iNDj0iaug?rel=0" width="560"></iframe>

<p>The second (and more exciting) kind of data moshes takes a certain kind of key frame from one video and replaces the same kind of frame in another video. All of the motion and some of the “re-drawings” of subsequent frames are pulled out of context, creating an effect that is a little surreal and unsettling. It’s not as precise as the pros do with their manual edits, but it also can automatically combine two sources in a way I’ve never seen before. (Here, I used Countdown again, and moshed it together with <a href="https://www.youtube.com/watch?v=pZ12_E5R3qc">Formation</a>.)</p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="315" loading="lazy" src="https://www.youtube-nocookie.com/embed/SARwUp1P7oQ?rel=0" width="560"></iframe>

<p>Again, I’ve muted the audio, but in this case it would normally play back Partition without any noticeable <a href="https://www.youtube.com/watch?v=56qgO0C82vY">flaws</a>.</p>

<h2 id="how-it-works">How it works</h2>

<p>This moshing technique relies on some facts about how the H.264 spec compresses and stores its data. It really is a remarkable standard, and if you’re not familiar it’s absolutely worth reading the tribute that is <a href="https://sidbala.com/h-264-is-magic/">“H.264 is Magic”</a>. The gist is that only a very small portion of frames, dubbed I-Frames, contain all the image data necessary to draw a full screen. The other kinds of frames, P- and B-Frames, have partial screens and “motion” data.</p>

<p>Other popular datamoshing techniques include removing I-Frames altogether or duplicating P-Frames so the same motion is re-applied to an image. In this example, instead, I’m replacing I-Frames with other I-Frames, and I’m doing it simply by copying and pasting the bytes from one into the place of another, truncating or padding out the data so it fits exactly.</p>

<p>The reason I can’t get only the motion from one video and only the “textures” from another is that the P-Frames blend those two types of data together into a single frame. If I could figure out some way to isolate the image data in the frame, or to re-encode a video to consist entirely of I- and B-Frames, I could probably get a wilder effect.</p>

<p>As it stands, the output of this script is a video that <em>plays</em>, but is pretty badly mangled. If you try to play it back in a client that shows you errors, you’ll see a lot of complaints. For compatibility’s sake, I’ve manually transcoded these videos into another format and back.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="beyonce" /><category term="programming" /><category term="python" /><category term="video" /><summary type="html"><![CDATA[Datamoshing is a glitch art technique applied to videos to intentionally create “pixel bleeding” and other digital motion artifacts. It became popular several years ago when it was used in near-simultaneous music videos by Chairlift and Kanye West. In those cases, and in the tutorials and techniques documented since then, the glitches are typically introduced to a single edited video, and done manually in a visual editing program.]]></summary></entry></feed>