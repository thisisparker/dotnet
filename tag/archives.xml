<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://thisisparker.github.io/dotnet/tag/archives.xml" rel="self" type="application/atom+xml" /><link href="https://thisisparker.github.io/dotnet/" rel="alternate" type="text/html" /><updated>2022-09-18T17:52:36-04:00</updated><id>https://thisisparker.github.io/dotnet/tag/archives.xml</id><title type="html">parker higgins dot net</title><subtitle></subtitle><author><name>Parker Higgins</name></author><entry><title type="html">Archiving threatened outlets for the Freedom of the Press Foundation</title><link href="https://thisisparker.github.io/dotnet/2018/03/archiving-threatened-outlets-for-the-freedom-of-the-press-foundation/" rel="alternate" type="text/html" title="Archiving threatened outlets for the Freedom of the Press Foundation" /><published>2018-03-12T23:07:24-04:00</published><updated>2018-03-12T23:07:24-04:00</updated><id>https://thisisparker.github.io/dotnet/2018/03/archiving-threatened-outlets-for-the-freedom-of-the-press-foundation</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2018/03/archiving-threatened-outlets-for-the-freedom-of-the-press-foundation/"><![CDATA[<p>A little over a month ago, I launched one of the Special Projects I’ve been working on at my new job at the <a href="https://freedom.press">Freedom of the Press Foundation</a>. The <a href="https://archive-it.org/collections/9790">Threatened Outlets collection at Archive-It</a> aims to capture the archives of news sites that we deem vulnerable to “the billionaire problem,” wherein wealthy individuals or organizations can eliminate unflattering coverage through litigation or by purchasing media companies altogether. From <a href="https://freedom.press/news/archiving-alternative-press-threatened-wealthy-buyers/">the launch announcement</a>:</p>

<blockquote>
  <p>Those efforts help individual journalists. But another important thing we can do to reduce the effectiveness of this kind of attack on press freedom is to commit ourselves to the wholesale preservation of threatened sites.</p>

  <p>In this case, we seek to reduce the “upside” for wealthy individuals and organizations who would eliminate embarrassing or unflattering coverage by purchasing outlets outright. In other words, we hope that sites that can’t simply be made to disappear will show some immunity to the billionaire problem.</p>
</blockquote>

<p>To my surprise and delight, our launch received some nice and encouraging coverage, in <a href="https://www.wired.com/story/gawker-archives-freedom-of-press-foundation-toast-la-weekly/">WIRED</a>, <a href="https://beta.techcrunch.com/2018/02/01/freedom-of-the-press-foundation-will-preserve-gawkers-archives/">TechCrunch</a>, <a href="https://thenextweb.com/insider/2018/01/31/meet-archivists-saving-alt-news-sites-permanent-deletion/">The Next Web</a>, <a href="https://www.nytimes.com/2018/02/01/business/media/gawker-archives-press-freedom.html">The New York Times</a>, and others. Sometimes when you’ve got your head down on something that feels like a niche topic, it’s nice to come up for air and realize that the general public is interested, too.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="archives" /><category term="freedom of the press foundation" /><category term="gawker" /><category term="internet archive" /><category term="journalism" /><category term="writing" /><summary type="html"><![CDATA[A little over a month ago, I launched one of the Special Projects I’ve been working on at my new job at the Freedom of the Press Foundation. The Threatened Outlets collection at Archive-It aims to capture the archives of news sites that we deem vulnerable to “the billionaire problem,” wherein wealthy individuals or organizations can eliminate unflattering coverage through litigation or by purchasing media companies altogether. From the launch announcement:]]></summary></entry><entry><title type="html">LinkArchiver, a new bot to back up tweeted links</title><link href="https://thisisparker.github.io/dotnet/2017/07/linkarchiver-a-new-bot-to-back-up-tweeted-links/" rel="alternate" type="text/html" title="LinkArchiver, a new bot to back up tweeted links" /><published>2017-07-11T16:10:04-04:00</published><updated>2017-07-11T16:10:04-04:00</updated><id>https://thisisparker.github.io/dotnet/2017/07/linkarchiver-a-new-bot-to-back-up-tweeted-links</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/07/linkarchiver-a-new-bot-to-back-up-tweeted-links/"><![CDATA[<p>Twitter users who want to ensure that the Wayback Machine has stored a copy of the pages they link to can now sign up with <a href="https://twitter.com/linkarchiver"><span class="citation">@LinkArchiver</span></a> to make it happen automatically. <span class="citation">@LinkArchiver</span> is the first project I’ve worked on in my 12-week stay at <a href="https://www.recurse.com/">Recurse Center</a>, where I’m learning to be a better programmer.</p>

<p>The idea for <span class="citation">@LinkArchiver</span> was <a href="https://twitter.com/j4cob/status/883054720260087808">suggested by my friend Jacob</a>. I liked it because it was useful, relatively simple, and combined things I knew (Python wrappers for the Twitter API) with things I didn’t (event-based programming, making a process run constantly in the background, and more). I did not expect it to get as enthusiastic a reaction as it has, but that’s also nice.</p>

<p>The entire bot is <a href="https://github.com/thisisparker/linkarchiver/">one short Python script</a> that uses the Twython library to listen to the <a href="https://dev.twitter.com/streaming/userstreams">Twitter User stream API</a>. This is the first of my Twitter bots that is at all “interactive”—every previous bot used the REST APIs to post, but can not engage with things in their timeline or tweeted at them.</p>

<p>That change meant I had to use a slightly different architecture than I’ve used before. Each of my previous bots were small and self-contained scripts that produced a tweet or two each time they run. That design means I can trigger them with a cron job that runs at regular intervals. By contrast, <span class="citation">@LinkArchiver</span> runs all the time, listening to its timeline and acting when it needs to. It doesn’t have much interactive behavior—when you tweet at it directly, it can reply with a Wayback link, but that’s it—but learning this kind of structure will enable me to do much more interactive bots in the future.</p>

<p>It also required that I figure out how to “daemonize” the script, so that it could run in the background when I wasn’t connected and restart in case it crashed (or when I restart the computer). I found this aspect surprisingly difficult; it seems like a really basic need, but the documentation for how to do this was not especially easy to find. I host my bots on a Digital Ocean box running Ubuntu, so this script is running as a systemd service. The <a href="https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units">Digital Ocean documentation</a> and this <a href="https://www.reddit.com/r/raspberry_pi/comments/4vhofs/creating_a_systemd_daemon_so_you_can_run_a_python/">Reddit tutorial</a> were both very helpful for my figuring it out.</p>

<p>Since launching the bot, I’ve gotten in touch with the folks at the Wayback Machine, and at their request added a custom user-agent. I was worried that the bot would get on their nerves, but they seem to really appreciate it—what a relief. After its first four days online, it’s tracking some 3,400 users and has sent about 25,000 links to the Internet Archive.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="archives" /><category term="bots" /><category term="internet archive" /><category term="programming" /><category term="python" /><category term="twitter" /><summary type="html"><![CDATA[Twitter users who want to ensure that the Wayback Machine has stored a copy of the pages they link to can now sign up with @LinkArchiver to make it happen automatically. @LinkArchiver is the first project I’ve worked on in my 12-week stay at Recurse Center, where I’m learning to be a better programmer.]]></summary></entry><entry><title type="html">Building Mastodon to be frozen</title><link href="https://thisisparker.github.io/dotnet/2017/04/building-mastodon-frozen/" rel="alternate" type="text/html" title="Building Mastodon to be frozen" /><published>2017-04-30T20:21:02-04:00</published><updated>2017-04-30T20:21:02-04:00</updated><id>https://thisisparker.github.io/dotnet/2017/04/building-mastodon-frozen</id><content type="html" xml:base="https://thisisparker.github.io/dotnet/2017/04/building-mastodon-frozen/"><![CDATA[<p>As the federated social network Mastodon has surged in popularity over the last month, <a href="https://instances.mastodon.xyz/">more than a thousand instances</a> — ranging from a single user to tens of thousands — have been started by the community.</p>

<p><img src="https://parkerhiggins.net/wp-content/uploads/2017/04/mastodon-logo-282x300.png" alt="" /></p>

<p>That’s a really great development in terms of decentralization and distribution, which bring a lot of benefits, but it also makes it a near certainty that a currently popular instance will go away. It could happen abruptly, if a sysadmin accidentally drops a database, or gradually, if it becomes to expensive or time-consuming to run, but it will happen.</p>

<p>Mastodon developers can make some choices now that could help preserve those communities — if only in a “frozen” form — after they are no longer active. And if done right, it could open up new possibilities for persistent presentation of ephemeral communities.</p>

<p>Specifically, Mastodon can develop a more robust option to export an entire instance in a format that can be served statically. The Mastodon instance would be frozen, in the sense that nobody could sign up or add new content to it, but its links could be preserved and the interactions could be saved. Serving a static version of the site in a dedicated viewer could be done cheaply, and organizations like the Internet Archive would likely step up to host significant defunct communities.</p>

<p>(Twitter sort of has an option like this on the individual level: users can <a href="https://support.twitter.com/articles/20170160">export their own archive</a>, and get a zip file that <em>looks</em> like Twitter but is all local.)</p>

<p>The historical benefits of that kind of feature are obvious to anybody who’s gone through old forums or mailing list posts. But if it were built out as a feature, I think more communities would find new creative ways of using the software. One that immediately comes to mind: Conferences could throw up an instance and create accounts for all the attendees. Once that instance was “frozen,” it’s a record of the backchannel like we haven’t really had before. Or in cases where they’ve gotten clear consent, researchers could parse the data to learn things about how the different ways in which individual communities communicate.</p>

<p>Obviously not every instance would want to get the preservation treatment, and instance admins would likely want to make clear what their long term plans are. And of course, this feature would have to be designed very carefully to respect the privacy preferences of people who participate. But for many networks, the present moment gets all the focus while the real value lies in each of those presents that have now become the past. Most social networks don’t stop to consider that fact. Mastodon, with its community focus, could.</p>

<p>There aren’t that many years of Web (or even Internet) history, but already those years haven’t been kind to online communities. <a href="https://www.wired.com/2010/11/geocities-lives-on-as-massive-torrent-download/">Archiveteam heroics</a> only go so far — designing for the long-term preservation of our spaces should be a priority.</p>]]></content><author><name>Parker Higgins</name></author><category term="Uncategorized" /><category term="archives" /><category term="mastodon" /><category term="social media" /><summary type="html"><![CDATA[As the federated social network Mastodon has surged in popularity over the last month, more than a thousand instances — ranging from a single user to tens of thousands — have been started by the community.]]></summary></entry></feed>